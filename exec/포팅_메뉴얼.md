# Install manual

# 배포과정

### 배포 환경

- Ubuntu:20.04
- GPU 16G 이상 
  - 충족되지 않더라도 사용 가능
- docker 20.10.16
  - GPU 요구사항 충족및 사용 nvidia-docker 설치 필요

## Frontend

### 사용 기술 및 버전

- 개발언어
  - React : 18.0.0
- IDE
  - VisualStudioCode: 1.67.2
- npm : 8.1.2
- node : v16.13.1

### /frontend 경로에 .env.local 파일 생성 후 아래 코드 입력

``` txt
REACT_APP_BASE_URL = {backend_url}
```



#### docker build & run

```bash
git clone [Repository Url]
cd frontend
docker build -t {frontend_name} .
```





## DB 실행 명령어

- DB는 docker hub의 mongodb:latest 를 다운받아 진행하였습니다.

  ``` bash
  docker run -d --name mongo -p 27017:27017 mongo
  ```

- deamon으로 돌린 후 추가적으로 DB설정이 필요합니다



### ERD

![ERD](포팅_메뉴얼.assets/ERD.jpg)



backend 폴더(manage.py와 같은 위치)에 `secrets.json` 파일을 만들고 아래의 내용을 추가합니다.

```
{
  "SECRET_KEY": "",
  "CIPHER_V1_KEY": "",
  "DATABASES": {
    "default": {
      "ENGINE": "djongo",
      "ENFORCE_SCHEMA": "True",
      "LOGGING": {
          "version": 1,
          "loggers": {
              "djongo": {
                  "level": "DEBUG",
                  "propogate": "False"
              }
          }
       },
      "NAME": "",
      "CLIENT": {
          "host": "",
          "port": 27017,
          "username": "",
          "password": "",
          "authSource": "",
          "authMechanism": "DEFAULT"
      }
    }
  }
}

```

- `SECRET_KEY` : 장고 프로젝트 생성시 `settings.py `에 등록되어 있는 키를 입력해 주시면 됩니다.
- `CIPHER_V1_KEY` : 암호화를 위한 32바이트 문자열을 입력하시면 됩니다. (영문 32자 등)
- `NAME` , `authSource`: mongoDB 데이터베이스 이름을 입력합니다.
- `host` : mongoDB의 host 주소를 입력합니다.
- `username` : mongoDB 사용 시 만든 유저이름을 입력합니다.
- `password` : mongoDB 사용 시 만든 비밀번호를 입력합니다.
- `port` : 기본 포트는 27017 이지만 변경하였다면 변경한 포트 번호를 입력합니다.





## Backend

### 사용 기술 및 버전

- 개발 언어
  - python 3.7.13
- IDE
  - Visual Studio Code 1.67.2
- 웹 프레임워크
  - django 3.2.13
- DB
  - mongoDB 5.0.8

- 그 외 사용된 패키지는 backend/all_requirements.txt에 들어있습니다.
  - 해당 파일은 ai와, django 서버를 구성하는 모든 모듈이 들어있습니다.



### BE 파일 실행 시 명령어

1. 현재 작성된 명령어는 AI와 BE가 함께 위치해 있을 때를 기준으로 합니다.

2. 현재 Git Repo에 올라간 AI 파일 중 kogpt.py와 Painterbot.py를 제외한 모델은 GPU사용을 하지 않고 구동이 가능하고, Dockerfile은 이에 맞춰서 작성되었습니다.

3. 사용자의 PC가 GPU 요구사항을 충족하고, 위 두 가지 모델을 사용하고 싶다면 Dockerfile의 수정이 필요합니다.

   #### FROM부분 수정

   ``` dockerfile
   FROM nvidia/cuda:11.0.3-base-ubuntu20.04
   ...
   # GPU 모델은 cuda 환경에서 진행을 해야 모델 구동이 가능합니다.
   # 따라서 GPU 모델을 사용하고 싶으신 분은 윗 줄과 같이 환경을 수정해주시기 바랍니다.
   ```

   

#### docker build & run

```bash
cd backend
docker build -t {backend_name} .

# GPU 사용시 구동 명령어
docker run -d --gpus all --name {backend_name} -p 8000:8000 be

# GPU 미 사용시 구동 명령어
docker run -d --name {backend_name} -p 8000:8000 be
```





## AI 

### 사용 기술 및 버전

- 개발 언어
  - python 3.7.13
- IDE
  - Visual Studio Code 1.67.2



### usage

서비스에서 사용하기전에 NLP와 TTS는 사전에 학습된 모델을 위치 시킨 후 진행하셔야 합니다.

#### NLP Save Model 

- SSIFI 에서 제공하는 기본모델 : `BASICBOT, NOVELBOT, WELLNESSBOT, PAINTERBOT, KAKAO-KOGPT `

  - BASICBOT 
    - Fine-Tuning 하지 않은 KoGPT2(SKT-KoGPT) Pretrained Model
  - NOVELBOT
    - 소설 데이터를 바탕으로 Fine-Tuning이 진행된 KoGPT2(SKT-KoGPT) Model
  - WELLNESSBOT
    - 심리상담 데이터를 바탕으로 Fine-Tuning이 진행된 KoGPT2(SKT-KoGPT) Model
  - PAINTBOT **GPU사용 모델**
    - Fine-Tuning 하지 않은 GLIDE-text2im Pretrained Model(Input 값으로 한국어 텍스트 사용불가)
  - KAKAO-KOGPT6B-ryan1.5b-float16  **GPU사용 모델**
    - KAKAO에서 제작되었으며 Fine-Tuning 하지 않은 Pretrained Model
    - half-precision(반정밀도)는 Volta, Turing 또는 Ampere 기반의 NVIDIA GPU가 필요합니다.
    - 최소 16GB 이상 GPU 메모리가 필요합니다. 

- 다음 명령어를 통해 제공 모델을 다운받을 수 있습니다. (모델 저장 위치 : `NLP/models`)

  ```
  python NLP/save_models.py
  ```

#### TTS Pretrained model

- acoustic model
  - pretrained model(checkpoint)을 [다운로드](https://drive.google.com/file/d/1qkFuNLqPIm-A5mZZDPGK1mnp0_Lh00PN/view?usp=sharing)해 주세요.
    그 후, `hparams.py`에 있는 `checkpoint_path` 변수에 기록된 경로에 위치시켜주시면 사전학습된 모델을 사용 하실 수 있습니다.
- vocoder
  - 학습된 VocGAN 모델을 [다운로드](https://drive.google.com/file/d/1GxaLlTrEhq0aXFvd_X1f4b-ev7-FH8RB/view?usp=sharing) 하여 `vocoder/pretrained_models/` 경로에 위치시킵니다.
